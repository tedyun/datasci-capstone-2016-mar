?readLines
con <- file("final/en_US.twitter.txt", "r")
readLines(con)
close(con)
con <- file("final/en_US/en_US.twitter.txt", "r")
readLines(con)
close(con)
con <- file("final/en_US/en_US.twitter.txt", "r")
dataset_twitter <- readLines(con)
close(con)
dim(dataset_twitter)
nrow(dataset_twitter)
summary(dataset_twitter)
con <- file("final/en_US/en_US.news.txt", "r")
dataset_news <- readLines(con)
close(con)
con <- file("final/en_US/en_US.blogs.txt", "r")
dataset_blogs <- readLines(con)
close(con)
dataset_twitter[0]
dataset_twitter[[0][]
dataset_twitter[[0]
]
dataset_twitter$1
dataset_twitter[[1]]
dataset_twitter[1]
str(dataset_twitter)
length(dataset_twitter)
length(dataset_twitter[1])
dataset_twitter[1]
nchar(dataset_twitter[1])
getMaximumLineLenght <- function (dataset) {
maxLength <- 0
for (line in dataset) {
curLength <- nchar(line)
if (curLength > maxLength) {
maxLength <- curLength
}
}
}
getMaximumLineLenght(dataset_twitter)
getMaximumLineLength <- function (dataset) {
maxLength <- 0
for (line in dataset) {
curLength <- nchar(line)
if (curLength > maxLength) {
maxLength <- curLength
}
}
return(maxLength)
}
getMaximumLineLenght(dataset_twitter)
getMaximumLineLength(dataset_twitter)
getMaximumLineLength(dataset_news)
getMaximumLineLength(dataset_blogs)
head(dataset_twitter)
line <- "When you meet someone special... you'll know. Your heart will beat more rapidly and you'll smile for no reason."
strsplit(line, " ")
strsplit(line, "[ \.]")
strsplit(line, "[ .]")
strsplit(line, "[^a-zA-Z0-9']")
?Filter
TRUE || FALSE
TRUE | FALSE
TRUE && FALSE
TRUE & FALSE
"a" == "a"
"a" == "b"
tokenizeLine <- function (line) {
tokens <- strsplit(line, "[^a-zA-Z0-9']")
tokenFilter <- function (word) {
if (
(nchar(word) == 0) ||
((nchar(word) == 0) && (tolower(word) != "a"))
) {
return(TRUE)
}
return(FALSE)
}
return(Filter(tokenFilter, tokens))
}
tokenizeLine(line)
tokenizeLine <- function (line) {
tokens <- strsplit(line, "[^a-zA-Z0-9']")
tokenFilter <- function (word) {
if (
(nchar(word) == 0) ||
((nchar(word) == 0) && (tolower(word) != "a"))
) {
return(FALSE)
}
return(TRUE)
}
return(Filter(tokenFilter, tokens))
}
tokenizeLine(line)
nchar("")
line
tokenizeLine <- function (line) {
tokens <- strsplit(line, "[^a-zA-Z0-9']")
tokenFilter <- function (word) {
if (
(nchar(word) == 0) ||
((nchar(word) == 1) && (tolower(word) != "a"))
) {
return(FALSE)
}
return(TRUE)
}
return(Filter(tokenFilter, tokens))
}
tokenizeLine(line)
tokenizeLine <- function (line) {
tokens <- strsplit(line, "[^a-zA-Z0-9'\-]")
tokenFilter <- function (word) {
if (
(nchar(word) == 0) ||
((nchar(word) == 1) && (tolower(word) != "a"))
) {
return(FALSE)
}
return(TRUE)
}
return(Filter(tokenFilter, tokens))
}
tokenizeLine <- function (line) {
tokens <- strsplit(line, "[^a-zA-Z0-9'\-]")
tokenFilter <- function (word) {
if (
(nchar(word) == 0) ||
((nchar(word) == 1) && (tolower(word) != "a"))
) {
return(FALSE)
}
return(TRUE)
}
return(Filter(tokenFilter, tokens))
}
strsplit(line, "[^a-zA-Z0-9'\-]")
strsplit(line, "[^a-zA-Z0-9'-]")
strsplit("abc def-ghi - gji asdfll asdfjklads fdasklaf", "[^a-zA-Z0-9'-]")
strsplit(line, "[^a-zA-Z0-9'-]")
unlist(strsplit(line, "[^a-zA-Z0-9'-]"))
tokenizeLine <- function (line) {
tokens <- unlist(strsplit(line, "[^a-zA-Z0-9'-]"))
tokenFilter <- function (word) {
if (
(nchar(word) == 0) ||
((nchar(word) == 1) && (tolower(word) != "a"))
) {
return(FALSE)
}
return(TRUE)
}
return(Filter(tokenFilter, tokens))
}
tokenizeLine(line)
"When" %in% tokenizeLine(line)
getNumberOfLinesWithWord <- function (dataset, word) {
count <- 0
for (line in dataset) {
tokens <- tokenizeLine(line)
if (word %in% tokens) {
count <- count + 1
}
}
return(maxLength)
}
getNumberOfLinesWithWord(dataset_twitter, "love")
getNumberOfLinesWithWord <- function (dataset, word) {
count <- 0
for (line in dataset) {
tokens <- tokenizeLine(line)
if (word %in% tokens) {
count <- count + 1
}
}
return(count)
}
getNumberOfLinesWithWord(dataset_twitter, "love")
c()
c(NULL, 'a')
c(c(NULL, 'a'), 'b')
1:5
getLinesContainingString <- function (dataset, keyword) {
lineNumbers <- NULL
for (i in 1:length(dataset)) {
line <- lineNumbers[i]
if (grep(keyword, line, fixed=TRUE)) {
lineNumbers <- c(lineNumbers, i)
}
}
}
loveLines <- getLinesContainingString(dataset_twitter, 'love')
grep('a', 'abc')
grep('d', 'abc')
length(grep('d', 'abc'))
getLinesContainingString <- function (dataset, keyword) {
lineNumbers <- NULL
for (i in 1:length(dataset)) {
line <- lineNumbers[i]
if (length(grep(keyword, line, fixed=TRUE)) > 0) {
lineNumbers <- c(lineNumbers, i)
}
}
}
loveLines <- getLinesContainingString(dataset_twitter, 'love')
getLinesContainingString <- function (dataset, keyword) {
lineNumbers <- NULL
for (i in 1:length(dataset)) {
line <- dataset[i]
if (length(grep(keyword, line, fixed=TRUE)) > 0) {
lineNumbers <- c(lineNumbers, i)
}
}
}
loveLines <- getLinesContainingString(dataset_twitter, 'love')
loveLines
getLinesContainingString <- function (dataset, keyword) {
lineNumbers <- NULL
for (i in 1:length(dataset)) {
line <- dataset[i]
if (length(grep(keyword, line, fixed=TRUE)) > 0) {
lineNumbers <- c(lineNumbers, i)
}
}
return(lineNumbers)
}
loveLines
loveLines <- getLinesContainingString(dataset_twitter, 'love')
loveLines
length(loveLines)
hateLines <- getLinesContainingString(dataset_twitter, 'hate')
length(loveLines) / length(hateLines)
biostatLines <- getLinesContainingString(dataset_twitter, 'biostats')
biostatLines
dataset_twitter[556872]
kickboxing <- getLinesContainingString(dataset_twitter, "A computer once beat me at chess, but it was no match for me at kickboxing")
kickboxing
