name4 <- names(docFreq)
search <- paste0(word1, "_", word2, "_", word3, "_")
indices <- which(substr(name4, 1, nchar(search)) == search)
result <- sort(docFreq[indices], decreasing = TRUE)
result <- result / sum(result)
result
}
predict3(gram4Freq, "you", "need", "is")
predict3(gram4Freq, "i", "love", "you")
predict3(gram4Freq, "a", "case", "of")
predict3(gram4Freq, "would", "mean", "the")
predict3(gram4Freq, "make", "me", "the")
predict3(gram4Freq, "date", "at", "the")
tail(gram4Freq)
trainingDFM4 <- dfm(trainingData[1:500000], toLower = TRUE, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = FALSE, language="english", ngrams=4)
gram4Freq <- docfreq(trainingDFM4)
predict3(gram4Freq, "a", "case", "of")
predict3 <- function (docFreq, word1, word2, word3) {
name4 <- names(docFreq)
search <- paste0(word1, "_", word2, "_", word3, "_")
indices <- which(substr(name4, 1, nchar(search)) == search)
result <- sort(docFreq[indices], decreasing = TRUE)
result <- result / sum(result)
result[1:5]
}
predict3(gram4Freq, "a", "case", "of")
predict3(gram4Freq, "would", "mean", "the")
predict3(gram4Freq, "make", "me", "the")
predict3(gram4Freq, "struggling", "but", "the")
predict3(gram4Freq, "date", "at", "the")
predict3 <- function (docFreq, word1, word2, word3) {
name4 <- names(docFreq)
search <- paste0(word1, "_", word2, "_", word3, "_")
indices <- which(substr(name4, 1, nchar(search)) == search)
result <- sort(docFreq[indices], decreasing = TRUE)
result <- result / sum(result)
result[1:min(5, length(result)]
}
predict3 <- function (docFreq, word1, word2, word3) {
name4 <- names(docFreq)
search <- paste0(word1, "_", word2, "_", word3, "_")
indices <- which(substr(name4, 1, nchar(search)) == search)
result <- sort(docFreq[indices], decreasing = TRUE)
result <- result / sum(result)
result[1:min(5, length(result))]
}
predict3(gram4Freq, "date", "at", "the")
predict3(gram4Freq, "be", "on", "my")
predict3(gram4Freq, "in", "quite", "some")
predict3(gram4Freq, "with", "his", "little")
predict3(gram4Freq, "faith", "during", "the")
predict3(gram4Freq, "you", "must", "be")
trainingDFM4 <- dfm(trainingData, toLower = TRUE, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = FALSE, language="english", ngrams=4)
gram4Freq <- docfreq(trainingDFM4)
saveRDS(gram4Freq, "gram4Freq.rds")
saveRDS(trainingDFM4, "trainingDFM4.rds")
rm(trainingDFM)
rm(trainingDFM4)
gc()
head(gram4Freq)
length(gram4Freq)
length(gram4Freq[gram4Freq != 1])
predict3(gram4Freq, "a", "case", "of")
predict3(gram4Freq, "would", "mean", "the")
predict3(gram4Freq, "struggling", "but", "the")
predict3(gram4Freq, "date", "at", "the")
predict3(gram4Freq, "be", "on", "my")
substr("abc", 1)
predict3 <- function (docFreq, word1, word2, word3) {
name4 <- names(docFreq)
search <- paste0(word1, "_", word2, "_", word3, "_")
indices <- which(substr(name4, 1, nchar(search)) == search)
result <- sort(docFreq[indices], decreasing = TRUE)
if (length(result) > 0) {
result <- result / sum(result)
result <- result[1:min(5, length(result))]
nm <- names(result)
names(result) <- substr(nm, nchar(search) + 1, nchar(nm))
}
result
}
predict3(gram4Freq, "be", "on", "my")
dropSmallNumbers <- function (docFreq, cutoff) {
docFreq[docFreq > cutoff]
}
gram4FreqDrop1 <- dropSmallNumbers(gram4Freq, 1)
rm(gram4Freq)
gc()
rm(twitter)
rm(blog)
rm(news)
rm(trainTwitter)
rm(trainNews)
rm(trainBlog)
rm(testBlog)
rm(testNews)
rm(testTwitter)
rm(search)
rm (nm)
gc()
predict3(gram4FreqDrop1, "in", "quite", "some")
predict3(gram4FreqDrop1, "with", "his", "little")
predict3(gram4FreqDrop1, "faith", "during", "the")
predict3(gram4FreqDrop1, "you", "must", "be")
saveRDS(gram4FreqDrop1, "gram4FreqDrop1.rds")
stopwords(kind = "english", verbose = FALSE)
predict3(gram4FreqDrop1, "i'd", "like", "to")
predict3(gram4FreqDrop1, "to", "the", "grocery")
predict3(gram4FreqDrop1, "killed", "by", "an")
trainingDFM3 <- dfm(trainingData, toLower = TRUE, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = FALSE, language="english", ngrams=3)
source("newAnalysis.R")
gram3Freq <- docfreq(trainingDFM3)
saveRDS(gram3Freq, "gram3Freq.rds")
rm(trainingDFM3)
gc()
gram3FreqDrop1 <- dropSmallNumbers(gram3Freq, 1)
saveRDS(gram3FreqDrop1, "gram3FreqDrop1.rds")
rm(gram3Freq)
gc()
predict2(gram3FreqDrop1, "case", "of")
predict2 <- function (docFreq3, word1, word2) {
name3 <- names(docFreq3)
search <- paste0(word1, "_", word2, "_")
indices <- which(substr(name3, 1, nchar(search)) == search)
result <- sort(docFreq3[indices], decreasing = TRUE)
if (length(result) > 0) {
result <- result / sum(result)
result <- result[1:min(3, length(result))]
nm <- names(result)
names(result) <- substr(nm, nchar(search) + 1, nchar(nm))
}
result
}
predict1 <- function (docFreq2, word1) {
name2 <- names(docFreq2)
search <- paste0(word1, "_", word2, "_")
indices <- which(substr(name2, 1, nchar(search)) == search)
result <- sort(docFreq2[indices], decreasing = TRUE)
if (length(result) > 0) {
result <- result / sum(result)
result <- result[1:min(3, length(result))]
nm <- names(result)
names(result) <- substr(nm, nchar(search) + 1, nchar(nm))
}
result
}
predict2(gram3FreqDrop1, "case", "of")
predict2(gram3FreqDrop1, "mean", "the")
predict2(gram3FreqDrop1, "me", "the")
predict2(gram3FreqDrop1, "but", "the")
predict2(gram3FreqDrop1, "at", "the")
predict2(gram3FreqDrop1, "on", "my")
predict2(gram3FreqDrop1, "quite", "some")
predict2(gram3FreqDrop1, "his", "little")
predict2(gram3FreqDrop1, "during", "the")
predict2(gram3FreqDrop1, "must", "be")
rm(testData)
rm(trainingData)
trainingDFM2 <- dfm(trainingData, toLower = TRUE, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = FALSE, language="english", ngrams=2)
saveRDS(trainingDFM2, "trainingDFM2.rds")
trainingData <- readRDS("trainingData.rds")
source("newAnalysis.R")
gram2Freq <- docfreq(trainingDFM2)
saveRDS(gram2Freq, "gram2Freq.rds")
gram2FreqDrop1 <- dropSmallNumbers(gram2Freq, 1)
saveRDS(gram2FreqDrop1, "gram2FreqDrop1.rds")
rm(trainingDFM2)
rm(gram2Freq)
gc()
rm(trainingData)
gc()
rm(gram2FreqDrop1)
rm(gram3FreqDrop1)
rm(gram4FreqDrop1)
gc()
library(quanteda)
?stopwords
stopwords("english")
source("newAnalysis.R")
gc()
gramClean3Freq <- docfreq(trainingCleanDFM3)
saveRDS(gramClean3Freq, "gramClean3Freq.rds")
gramClean3FreqDrop1 <- dropSmallNumbers(gramClean3Freq, 1)
saveRDS(gramClean3FreqDrop1, "gramClean3FreqDrop1")
rm(trainingCleanDFM3)
predict("When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd", gramClean3FreqDrop1, 2)
source("prediction.R")
predict("When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd", gramClean3FreqDrop1, 2)
text <- "When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd"
tokens <- removeFeatures(tokenize(text, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = FALSE), stopwords("english"))
tokens
tokens <- tokens[(length(tokens) - ngram + 1):length(tokens)]
tokens <- tokens[(length(tokens) - 2 + 1):length(tokens)]
tokens
tokens <- removeFeatures(tokenize(text, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = FALSE), stopwords("english"))
tokens[[1]]
tokens <- removeFeatures(tokenize(text, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = FALSE), stopwords("english"))[[1]]
tokens
tokens <- tokens[(length(tokens) - 2 + 1):length(tokens)]
tokens
predict("When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd", gramClean3FreqDrop1, 2)
source("prediction.R")
predict("When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd", gramClean3FreqDrop1, 2)
gramClean3FreqDrop1[1:5]
predict("yes prime and or minister", gramClean3FreqDrop1, 2)
predict("moment and right and and now", gramClean3FreqDrop1, 2)
predict("I moment and or right", gramClean3FreqDrop1, 2)
predict("maya and and never or I'd get", gramClean3FreqDrop1, 2)
predict("may and and I'd never", gramClean3FreqDrop1, 2)
rm(gramClean3Freq)
rm(gramClean3FreqDrop1)
rm(trainingData)
source("newAnalysis.R")
gc()
gram5Freq <- docfreq(trainingDFM5)
saveRDS(gram5Freq, "gram5Freq.rds")
rm(trainingData)
rm(trainingDFM5)
gc()
gram5FreqDrop1 <- dropSmallNumbers(gram5Freq, 1)
saveRDS(gram5FreqDrop1, "gram5FreqDrop1.rds")
rm(gram5Freq)
gc()
source("predict.R")
source("prediction.R")
predict("want to be the air for you. I'll be there for you, I'd live and I'd", gram5FreqDrop1, 4)
source("prediction.R")
predict("he started telling me about his", gram5FreqDrop1, 4)
rm(gram5FreqDrop1)
rm(text)
rm(tokens)
install.packages("quanteda", dependencies=TRUE)
install.packages("shiny", dependencies=TRUE)
?page
library(shiny)
?page
?shinyUI
runApp("prediction_app")
runApp("prediction_app")
runApp("prediction_app")
runApp("prediction_app")
runApp("prediction_app")
runApp("prediction_app")
runApp("prediction_app")
?isolate
runApp("prediction_app")
runApp("prediction_app")
?withProgress
runApp("prediction_app")
runApp("prediction_app")
runApp("prediction_app")
library(shiny)
runApp("prediction_app")
library(hash)
library(quanteda)
library(permute)
install.packages("permute", dependencies = TRUE)
# gram2FreqDrop1 <- dropSmallNumbers(gram2Freq, 1)
# saveRDS(gram2FreqDrop1, "gram2FreqDrop1.rds")
gram2FreqDrop1 <- readRDS("gram2FreqDrop1.rds")
# drop all numbers smaller than or equal to the cutoff
dropSmallNumbers <- function (docFreq, cutoff) {
docFreq[docFreq > cutoff]
}
gram2FreqDrop1 <- readRDS("gram2FreqDrop1.rds")
gram2FreqDrop4 <- dropSmallNumbers(gram2FreqDrop1, 4)
saveRDS(gram2FreqDrop4, "gram2FreqDrop4.rds")
trainingData <- readRDS("trainingData.rds")
trainingDFM1 <- dfm(trainingData, toLower = TRUE, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = FALSE, language="english", ngrams=1)
saveRDS(trainingDFM1, "trainingDFM1.rds")
rm(trainingData)
gram1Freq <- docfreq(trainingDFM1)
saveRDS(gram1Freq, "gram1Freq.rds")
head(sort(gram1Freq))
head(sort(gram1Freq, decreasing=TRUE))
install.packages("goodTuring", dependencies = TRUE)
install.packages("edgeR", dependencies = TRUE)
source("https://bioconductor.org/biocLite.R")
biocLite("edgeR")
ls
library(edgeR)
gram2Freq <- readRDS("gram2Freq.rds")
gram2FreqSmooth <- goodTuring(gram2Freq)
head(gram2FreqSmooth$count)
summary(gram2FreqSmooth$count)
tail(gram2FreqSmooth$count)
head(names(gram2FreqSmooth$count))
head(gram2FreqSmooth$proportion)
legnth(gram2FreqSmooth$count)
length(gram2FreqSmooth$count)
length(gram2FreqSmooth$proportion)
length(gram2Freq)
gram2FreqSmooth$count[100]
gram2FreqSmooth$count[534345]
gram2FreqSmooth$count[53434]
gram2FreqSmooth$count[5343]
gram2FreqSmooth$count[534]
gram2FreqSmooth$count[1000]
gram2FreqSmooth$count[1001]
gram2FreqSmooth$count[3574]
gram2FreqSmooth$proportion[3574]
gram2FreqSmooth$proportion[300]
gram2FreqSmooth$proportion[1309]
gram2FreqSmooth$n
head(gram2FreqSmooth$n)
gramFreqLight <- list()
gramFreqLight[[2]] <- readRDS("gram2FreqDrop4.rds")
gramFreqLight[[3]] <- readRDS("gram3FreqDrop1.rds")
gramFreqLight[[4]] <- readRDS("gram4FreqDrop1.rds")
gramFreqLight[[5]] <- readRDS("gram5FreqDrop1.rds")
saveRDS(gramFreqLight, "gramFreqLight.rds")
v <- c(1, 2, 3, 4, 5)
names(v) <- c("a", "b", "c", "d", "e")
v
v[c("a","b")]
v[-c("a","b")]
v[1:2]
v[-1:2]
fil <- c("a","b")
names(v) %in% fil
!(names(v) %in% fil)
v[!(names(v) %in% fil)]
source('D:/Workspace/coursera-datasci/datasci-capstone-2016-mar/prediction.R')
dropSmallNumbers <- function (docFreq, cutoff) {
docFreq[docFreq > cutoff]
}
gramFreqLight <- list()
gramFreqLight[[2]] <- dropSmallNumbers(readRDS("gram2FreqDrop1.rds"), 4)
gramFreqLight[[3]] <- dropSmallNumbers(readRDS("gram3FreqDrop1.rds"), 3)
gramFreqLight[[4]] <- dropSmallNumbers(readRDS("gram4FreqDrop1.rds"), 2)
gramFreqLight[[5]] <- dropSmallNumbers(readRDS("gram5FreqDrop1.rds"), 1)
saveRDS(gramFreqLight, "gramFreqLight.rds")
3^2
counter <- 1
0.4^counter
0.4^(counter - 1)
predict <- function (tokens, docFreq, ngram, maxSuggest, excludeWords) {
if (length(tokens) < ngram) {
return(character())
}
tokens <- tokens[(length(tokens) - ngram + 1):length(tokens)]
search <- paste(tokens, collapse="_")
search <- paste0(search, "_")
vectnames <- names(docFreq)
indices <- which(substr(vectnames, 1, nchar(search)) == search)
result <- sort(docFreq[indices], decreasing = TRUE)
if (length(result) > 0) {
result <- result / sum(result)
cutLength <- maxSuggest + length(excludeWords)
result <- result[1:min(cutLength, length(result))]
nm <- names(result)
names(result) <- substr(nm, nchar(search) + 1, nchar(nm))
# exclude words
if (length(excludeWords) > 0) {
result <- result[!(names(result) %in% excludeWords)]
}
}
result[1:min(maxSuggest, length(result))]
}
alpha <- 0.4
predictStupidBackoff <- function (text) {
prediction <- character()
text  <- tolower(text)
tokens <- tokenize(text, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = FALSE)[[1]]
len <- length(tokens)
if (len < 1) {
return(prediction)
}
result <- numeric()
counter <- 0
for (n in min(5, len + 1):2) {
counter <- counter + 1
print(paste("Trying", n, "gram.."))
maxSuggest <- counter * 3
result <- c(result, alpha^(counter - 1) * predict(tokens, gramFreqLight[[n]], n - 1, maxSuggest, result))
}
result <- sort(result, decreasing = TRUE)
result <- result[1:min(3, length(result))]
#   if (length(result) > 0) {
#     prediction <- names(result)[1:min(3, length(result))]
#   }
return(result)
}
predictStupidBackoff("have a good")
predictStupidBackoff("I'm going to have a case of")
predictStupidBackoff("drink a case of")
predict <- function (tokens, docFreq, ngram, maxSuggest, excludeWords) {
if (length(tokens) < ngram) {
return(character())
}
tokens <- tokens[(length(tokens) - ngram + 1):length(tokens)]
search <- paste(tokens, collapse="_")
search <- paste0(search, "_")
vectnames <- names(docFreq)
indices <- which(substr(vectnames, 1, nchar(search)) == search)
result <- sort(docFreq[indices], decreasing = TRUE)
if (length(result) > 0) {
result <- result / sum(result)
cutLength <- maxSuggest + length(excludeWords)
result <- result[1:min(cutLength, length(result))]
nm <- names(result)
names(result) <- substr(nm, nchar(search) + 1, nchar(nm))
# exclude words
if (length(excludeWords) > 0) {
result <- result[!(names(result) %in% excludeWords)]
}
}
result <- result[1:min(maxSuggest, length(result))]
print(result)
result
}
alpha <- 0.4
predictStupidBackoff <- function (text) {
prediction <- character()
text  <- tolower(text)
tokens <- tokenize(text, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = FALSE)[[1]]
len <- length(tokens)
if (len < 1) {
return(prediction)
}
result <- numeric()
counter <- 0
for (n in min(5, len + 1):2) {
counter <- counter + 1
print(paste("Trying", n, "gram.."))
maxSuggest <- counter * 3
result <- c(result, alpha^(counter - 1) * predict(tokens, gramFreqLight[[n]], n - 1, maxSuggest, result))
}
result <- sort(result, decreasing = TRUE)
result <- result[1:min(3, length(result))]
#   if (length(result) > 0) {
#     prediction <- names(result)[1:min(3, length(result))]
#   }
return(result)
}
predictStupidBackoff("drink a case of")
predictStupidBackoff <- function (text) {
prediction <- character()
text  <- tolower(text)
tokens <- tokenize(text, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = FALSE)[[1]]
len <- length(tokens)
if (len < 1) {
return(prediction)
}
result <- numeric()
counter <- 0
excludeWords <- character()
for (n in min(5, len + 1):2) {
counter <- counter + 1
print(paste("Trying", n, "gram.."))
maxSuggest <- counter * 3
result <- c(result, alpha^(counter - 1) * predict(tokens, gramFreqLight[[n]], n - 1, maxSuggest, excludeWords))
excludeWords <- c(excludeWords, names(result))
}
result <- sort(result, decreasing = TRUE)
result <- result[1:min(3, length(result))]
#   if (length(result) > 0) {
#     prediction <- names(result)[1:min(3, length(result))]
#   }
return(result)
}
predictStupidBackoff("drink a case of")
grepl("[a-zA-Z]*", "abcsdf")
grepl("[a-zA-Z]*", "Ã¢")
grepl("[^a-zA-Z]+", "Ã¢")
grepl("[^a-zA-Z]+", "abc")
grepl("[^a-zA-Z_']+", "abcAsdfklj adsflkj ASDF asdf")
grepl("[^a-zA-Z_' ]+", "abcAsdfklj adsflkj ASDF asdf")
grepl("[^a-zA-Z_' ]+", "Ã¢")
grepl("[^a-zA-Z_' ]+", c("Ã", "a", "sdfa", "adf_asdf"))
!grepl("[^a-zA-Z_' ]+", c("Ã", "a", "sdfa", "adf_asdf"))
!grepl("[^a-zA-Z_'\- ]+", c("Ã", "a", "sdfa", "adf_asdf"))
!grepl("[^-a-zA-Z_' ]+", c("Ã", "a", "sdfa", "adf_asdf"))
cleanVector <- function (vec) {
nm <- names(vec)
fil <- !grepl("[^-a-zA-Z_' ]+", nm)
return(vec[fil])
}
cleanVector <- function (vec) {
nm <- names(vec)
fil <- !grepl("[^-a-zA-Z_' ]+", nm)
return(vec[fil])
}
gramFreqLight <- list()
gramFreqLight[[2]] <- cleanVector(dropSmallNumbers(readRDS("gram2FreqDrop1.rds"), 4))
gramFreqLight[[3]] <- cleanVector(dropSmallNumbers(readRDS("gram3FreqDrop1.rds"), 3))
gramFreqLight[[4]] <- cleanVector(dropSmallNumbers(readRDS("gram4FreqDrop1.rds"), 2))
gramFreqLight[[5]] <- cleanVector(dropSmallNumbers(readRDS("gram5FreqDrop1.rds"), 1))
saveRDS(gramFreqLight, "gramFreqLight.rds")
predictStupidBackoff("drink a case of")
saveRDS(gramFreqLight, "gramFreqLight.rds")
shiny::runApp('prediction_app')
shiny::runApp('prediction_app')
shiny::runApp('prediction_app')
shiny::runApp('prediction_app')
shiny::runApp('prediction_app')
head(sort(gram1Freq))
head(sort(gram1Freq, decreasing = TRUE))
shiny::runApp('prediction_app')
rm(alpha)
rm(counter)
rm(fil)
rm(gram1Freq)
rm(gram2Freq)
rm(gram2FreqDrop1)
rm(gram2FreqDrop4)
rm(gram2FreqSmooth)
rm(gramFreq)
rm(gramFreqLight)
rm(trainingDFM1)
rm(v)
gc()
